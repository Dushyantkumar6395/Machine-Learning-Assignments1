{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c826c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. In order to predict house price based on several characteristics, such as location, square footage,\n",
    "# number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this\n",
    "# situation would be the best to employ?\n",
    "# Dataset link:\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Example code (assuming data preprocessing and splitting)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Train SVR model\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predict house prices\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfa220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as\n",
    "# your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price\n",
    "# of a house as accurately as possible?\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Example code (assuming data preprocessing and splitting)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Train SVR model\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predict house prices\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate\n",
    "# regression metric to use with your SVM model. Which metric would be the most appropriate in this\n",
    "# scenario?\n",
    "\n",
    "# When dealing with a dataset that contains a significant number of outliers, the most appropriate regression metric to use with your SVM model would be the **Mean Absolute Error (MAE)**.\n",
    "\n",
    "# ### Reasoning:\n",
    "\n",
    "# 1. **Mean Absolute Error (MAE)**:\n",
    "#    - **Definition**: MAE measures the average absolute difference between predicted values and actual values.\n",
    "#    - **Robustness to Outliers**: MAE is less sensitive to outliers compared to other metrics like Mean Squared Error (MSE) because it does not involve squaring the differences.\n",
    "#    - **Interpretation**: MAE provides a more balanced view of prediction errors across the dataset, giving equal weight to all errors regardless of their magnitude.\n",
    "#    - **Suitability for Outliers**: Since outliers can significantly affect MSE (due to squaring), MAE is preferred when the dataset contains outliers as it provides a more reliable measure of prediction accuracy.\n",
    "\n",
    "# 2. **Alternative Metrics**:\n",
    "#    - **Mean Squared Error (MSE)**: MSE squares the differences between predicted and actual values, making it more sensitive to outliers.\n",
    "#    - **R-squared (Coefficient of Determination)**: R-squared is a measure of how well the model fits the data but doesn't directly account for outlier effects on prediction accuracy.\n",
    "\n",
    "# 3. **Application to SVM Regression**:\n",
    "#    - SVM regression models aim to minimize prediction errors. When outliers are present, using MAE ensures that the evaluation metric remains robust and does not overly penalize the model for predictions that deviate due to outliers.\n",
    "#    - MAE provides a clearer indication of how well the SVM model predicts the majority of data points, reflecting its robustness in the presence of outliers.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Example code (assuming data preprocessing and splitting)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize SVR model\n",
    "svr = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Train SVR model\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predict house prices\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "```\n",
    "\n",
    "# In summary, when working with a dataset that includes significant outliers, choosing MAE as the regression metric for evaluating your SVM model ensures a more robust assessment of prediction accuracy, mitigating the impact of outliers on the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best\n",
    "# metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values\n",
    "# are very close. Which metric should you choose to use in this case?\n",
    "\n",
    "# When both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) values are very close after evaluating an SVM regression model with a polynomial kernel, **RMSE** would be the more appropriate metric to choose. Here's why:\n",
    "\n",
    "# ### Reasoning:\n",
    "\n",
    "# 1. **Root Mean Squared Error (RMSE)**:\n",
    "#    - **Definition**: RMSE is the square root of the average of squared differences between predicted values and actual values.\n",
    "#    - **Interpretation**: RMSE is directly interpretable in the same units as the target variable (house prices in this case), which makes it easier to understand in practical terms.\n",
    "#    - **Preferability**: While MSE and RMSE often yield similar values, RMSE provides a clearer indication of the average magnitude of errors in the predicted values due to its square root transformation.\n",
    "#    - **Sensitivity to Large Errors**: RMSE is more sensitive to large errors compared to MSE, which might be crucial for understanding the impact of larger prediction errors in a polynomial SVM model.\n",
    "\n",
    "# 2. **Mean Squared Error (MSE)**:\n",
    "#    - **Definition**: MSE is the average of squared differences between predicted values and actual values.\n",
    "#    - **Interpretation**: MSE quantifies the average squared deviation between predicted and actual values, but its squared nature makes it less directly interpretable in the context of prediction errors.\n",
    "\n",
    "# 3. **Application to SVM Regression**:\n",
    "#    - SVM regression models aim to minimize the error between predicted and actual values. When using a polynomial kernel, which can sometimes lead to non-linear relationships between features and targets, RMSE provides a more intuitive measure of how well the model's predictions align with the actual values.\n",
    "#    - RMSE's ability to directly indicate the typical size of errors in prediction (in the same units as the target variable) makes it preferable for assessing the performance of SVM regression models.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "# ```python\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Example code (assuming data preprocessing and splitting)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize SVR model with polynomial kernel\n",
    "svr_poly = SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "\n",
    "# Train SVR model\n",
    "svr_poly.fit(X_train, y_train)\n",
    "\n",
    "# Predict house prices\n",
    "y_pred = svr_poly.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "```\n",
    "\n",
    "# In this scenario, even though MSE and RMSE are close, RMSE would provide a slightly better perspective on the average prediction error due to its direct interpretation in the units of the target variable. Therefore, RMSE should be chosen to evaluate the performance of your SVM regression model with a polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. You are comparing the performance of different SVM regression models using different kernels (linear,\n",
    "# polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most\n",
    "# appropriate if your goal is to measure how well the model explains the variance in the target variable?\n",
    "\n",
    "If your goal is to measure how well the SVM regression models explain the variance in the target variable across different kernels (linear, polynomial, and RBF), the most appropriate evaluation metric would be **R-squared (Coefficient of Determination)**.\n",
    "\n",
    "### Reasoning:\n",
    "\n",
    "1. **R-squared (Coefficient of Determination)**:\n",
    "   - **Definition**: R-squared is a statistical measure that represents the proportion of the variance in the dependent variable (target variable) that is explained by the independent variables (features) in the model.\n",
    "   - **Interpretation**: R-squared values range from 0 to 1, where:\n",
    "     - 0 indicates that the model does not explain any of the variance in the target variable.\n",
    "     - 1 indicates that the model perfectly explains the variance in the target variable.\n",
    "   - **Suitability**: R-squared is particularly useful when comparing models with different kernels (linear, polynomial, RBF) as it provides a standardized measure of how well each model fits the data.\n",
    "   - **Comparative Analysis**: Higher R-squared values indicate better model fit and better ability of the model to explain the variance in the target variable.\n",
    "\n",
    "2. **Alternative Metrics**:\n",
    "   - **Mean Squared Error (MSE)**: Measures the average squared difference between predicted values and actual values. It doesn't directly measure how well the model explains variance but rather the magnitude of prediction errors.\n",
    "   - **Root Mean Squared Error (RMSE)**: Similar to MSE but interpretable in the same units as the target variable. Like MSE, it focuses on prediction error magnitude rather than variance explanation.\n",
    "   - **Mean Absolute Error (MAE)**: Measures the average absolute difference between predicted values and actual values. Similar to MSE and RMSE, it focuses on error magnitude rather than variance explanation.\n",
    "\n",
    "3. **Application to SVM Regression**:\n",
    "   - SVM regression models aim to minimize prediction errors. When comparing different kernels, R-squared helps in understanding which kernel type (linear, polynomial, RBF) provides the best fit to the variance in the target variable.\n",
    "   - R-squared is especially valuable when interpreting complex relationships captured by non-linear kernels like polynomial and RBF, as it directly quantifies the amount of variance explained beyond simple linear relationships.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Example code (assuming data preprocessing and splitting)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# Initialize SVM regression models with different kernels\n",
    "svr_linear = SVR(kernel='linear', C=1.0)\n",
    "svr_poly = SVR(kernel='poly', degree=3, C=1.0, epsilon=0.1)\n",
    "svr_rbf = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "\n",
    "# Train SVM models\n",
    "svr_linear.fit(X_train, y_train)\n",
    "svr_poly.fit(X_train, y_train)\n",
    "svr_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Predict house prices for each model\n",
    "y_pred_linear = svr_linear.predict(X_test)\n",
    "y_pred_poly = svr_poly.predict(X_test)\n",
    "y_pred_rbf = svr_rbf.predict(X_test)\n",
    "\n",
    "# Calculate R-squared for each model\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "r2_rbf = r2_score(y_test, y_pred_rbf)\n",
    "\n",
    "print(f\"R-squared (Linear Kernel): {r2_linear:.2f}\")\n",
    "print(f\"R-squared (Polynomial Kernel): {r2_poly:.2f}\")\n",
    "print(f\"R-squared (RBF Kernel): {r2_rbf:.2f}\")\n",
    "```\n",
    "\n",
    "In conclusion, when evaluating how well SVM regression models explain the variance in the target variable across different kernels, R-squared provides a comprehensive and standardized metric to assess model performance. It helps in comparing and selecting the kernel type that best fits the data and explains the variance in the target variable effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe6ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
